{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/LangChain-Tutorials/blob/main/LangChain_Output_Parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV1rzv4pfn8o"
      },
      "source": [
        "In this notebook, we will learn how to use LangChain's output parser to process LLM output in a more programming language friendly way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3scUGKX6fh94"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain openai -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wqIvBtegME0"
      },
      "source": [
        "# CommaSeparatedListOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hLxERwUAgI02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
            "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lenovo\\Desktop\\LangChainPlayGround\\DeeperTutorials\\.env\n",
            "sk-lANo2jIeCWQt94UCCf5d16B7C32744279bF98b06C822D519\n"
          ]
        }
      ],
      "source": [
        "import os,sys\n",
        "import openai\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "# sys.path.append(\"../..\")\n",
        "\n",
        "# 读取本地/项目的环境变量。\n",
        "\n",
        "# find_dotenv()寻找并定位.env文件的路径\n",
        "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中  \n",
        "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
        "print(find_dotenv())\n",
        "_ = load_dotenv(find_dotenv())\n",
        "print(os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n",
        "\n",
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dA7lnAUkg0O0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n",
            "\n",
            "\n",
            "Java, C++, Python\n",
            "['Java', 'C++', 'Python']\n"
          ]
        }
      ],
      "source": [
        "output_parser = CommaSeparatedListOutputParser()\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "prompt = PromptTemplate(\n",
        "    template=\"List 3 main-stream {subject}.\\n{format_instructions}\",\n",
        "    input_variables=[\"subject\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")\n",
        "print(format_instructions)\n",
        "\n",
        "llm = OpenAI(\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "_input = prompt.format(subject=\"programming language\")\n",
        "# _input = prompt.format(subject=\"music styles\")\n",
        "output = llm(_input)\n",
        "print(output)\n",
        "\n",
        "finall = output_parser.parse(output)\n",
        "print(finall)\n",
        "\n",
        "# llm = ChatOpenAI()\n",
        "# prompt = ChatPromptTemplate.from_template(\"List 3 main-stream {subject}.\\n\")\n",
        "\n",
        "# chain = prompt | llm | output_parser\n",
        "# print(chain.invoke(\"music styles\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9M4boioiSAa"
      },
      "source": [
        "# EnumOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "W08I3jHDicmR"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers.enum import EnumOutputParser\n",
        "from enum import Enum\n",
        "\n",
        "class Genders(Enum):\n",
        "    MALE = \"male\"\n",
        "    FEMALE = \"female\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XelNJSDJilxD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select one of the following options: male, female\n",
            "\n",
            "male\n",
            "Genders.MALE\n"
          ]
        },
        {
          "ename": "OutputParserException",
          "evalue": "Response 'xyz' is not one of the expected values: ['male', 'female']",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32md:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\output_parsers\\enum.py:28\u001b[0m, in \u001b[0;36mEnumOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menum(response\u001b[39m.\u001b[39;49mstrip())\n\u001b[0;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
            "File \u001b[1;32md:\\Anaconda3\\envs\\LLM\\lib\\enum.py:385\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[1;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# simple value lookup\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__new__\u001b[39;49m(\u001b[39mcls\u001b[39;49m, value)\n\u001b[0;32m    386\u001b[0m \u001b[39m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n",
            "File \u001b[1;32md:\\Anaconda3\\envs\\LLM\\lib\\enum.py:710\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 710\u001b[0m     \u001b[39mraise\u001b[39;00m ve_exc\n\u001b[0;32m    711\u001b[0m \u001b[39melif\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mValueError\u001b[0m: 'xyz' is not a valid Genders",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(output)\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(output_parser\u001b[39m.\u001b[39mparse(output))\n\u001b[1;32m---> 16\u001b[0m output_parser\u001b[39m.\u001b[39;49mparse(\u001b[39m'\u001b[39;49m\u001b[39mxyz\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(output_parser)\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(output_parser\u001b[39m.\u001b[39mparse(\u001b[39m'\u001b[39m\u001b[39mmale\u001b[39m\u001b[39m'\u001b[39m))\n",
            "File \u001b[1;32md:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\output_parsers\\enum.py:30\u001b[0m, in \u001b[0;36mEnumOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menum(response\u001b[39m.\u001b[39mstrip())\n\u001b[0;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     31\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mResponse \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not one of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected values: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_values\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m     )\n",
            "\u001b[1;31mOutputParserException\u001b[0m: Response 'xyz' is not one of the expected values: ['male', 'female']"
          ]
        }
      ],
      "source": [
        "output_parser = EnumOutputParser(enum=Genders)\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Tell me the gender of the celebrity {name}.\\n{format_instructions}\",\n",
        "    input_variables=[\"name\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")\n",
        "print(format_instructions)\n",
        "\n",
        "_input = prompt.format(name=\"Michael Jordan\")\n",
        "output = llm(_input)\n",
        "print(output)\n",
        "\n",
        "print(output_parser.parse(output))\n",
        "\n",
        "# output_parser.parse('xyz')\n",
        "print(output_parser)\n",
        "print(output_parser.parse('male'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgYMfxcYjQ4E"
      },
      "source": [
        "# StructuredOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pdozG2V4jcTO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"answer\": string  // answer to the human's question\n",
            "\t\"source\": string  // source used to answer the human's question, should be a website.\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"answer\": \"Milk is typically made up of water, fat, proteins, lactose (sugar) and minerals.\",\n",
            "\t\"source\": \"https://www.dairynz.co.nz/nutrition/what-is-in-milk/\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"answer\", description=\"answer to the human's question\"),\n",
        "    ResponseSchema(name=\"source\", description=\"source used to answer the human's question, should be a website.\")\n",
        "]\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(format_instructions)\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
        "    input_variables=[\"question\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")\n",
        "\n",
        "\n",
        "_input = prompt.format_prompt(question=\"what are the ingredients of milk?\")\n",
        "output = llm(_input.to_string())\n",
        "\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VHcXhoiUj1aG"
      },
      "outputs": [],
      "source": [
        "json_data = output_parser.parse(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4cb1BQ2ypHU",
        "outputId": "7c9c99cf-bb3c-47a3-b7ec-c155e047e2aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Milk is typically made up of water, fat, proteins, lactose (sugar) and minerals.\n"
          ]
        }
      ],
      "source": [
        "print(json_data['answer'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONPJCAwPx0Wq0HDbOoi4Tk",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
