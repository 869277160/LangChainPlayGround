{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/LangChain-Tutorials/blob/main/Langchain_HuggingFacePipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 在langchain中集成hugging face pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRlP9ClDf1ZO",
        "outputId": "01ea1738-45ed-46b6-f9d0-21112d0eab6b"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjEafRssgBrZ",
        "outputId": "359faf05-3796-44a1-8625-191aab4f918b"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "model_id = \"facebook/bart-large-cnn\"\n",
        "task = \"summarization\"\n",
        "\n",
        "llm = HuggingFacePipeline.from_model_id(model_id=model_id, task=task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cAONy66ugTF2"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "template = \"\"\"{input}\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"input\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "question = \"\"\"\n",
        "The U.S. will be looking to snag their third straight World Cup title — and its fifth overall.\n",
        "\n",
        "The U.S. women's national team (USWNT) has held the No. 1 spot in FIFA's rankings for years, and is the odds-on favorite to win once again. But this year's tournament is considered fairly wide open, with several teams having a decent shot at the title.\n",
        "\n",
        "Indeed, the U.S. has had an interesting pattern of late: winning the World Cup, but losing at the Olympics. The USWNT won the World Cup in 2015, then failed to medal at the 2016 Olympics. They won the 2019 World Cup, then took home the bronze at the Tokyo Olympics in 2021.\n",
        "\"\"\"\n",
        "answer = llm_chain.run(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "p8Ea9uirJlAV",
        "outputId": "5de888e9-e615-465c-86f9-658345f48578"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The U.S. women's national team is the odds-on favorite to win this year's World Cup. The USWNT won the World Cup in 2015, then failed to medal at the 2016 Olympics. They won the 2019 World Cup, then took home the bronze at the Tokyo Olympics in 2021.\""
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGH563-IJnB4",
        "outputId": "1289a7ca-4c0d-4012-cebe-9425ec383ae4"
      },
      "outputs": [],
      "source": [
        "len(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV-0jxQjJoYd",
        "outputId": "d5bc81fa-1f29-4cb9-a053-362c68260c3a"
      },
      "outputs": [],
      "source": [
        "len(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iyfud0nDgFLm",
        "outputId": "2a7c8dce-5bac-47e1-9ae2-cd0084951246"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "template = \"\"\"\n",
        "你精通多种语言，是专业的翻译官。你负责{src_lang}到{dst_lang}的翻译工作。\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt.format(src_lang=\"英文\", dst_lang=\"中文\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do0XSG1Xo01P"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N34Z4R7po3Qd",
        "outputId": "cc7c54f1-597b-4909-95ce-6f4084c05618"
      },
      "outputs": [],
      "source": [
        "template=\"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "system_message_prompt.format(input_language=\"English\", output_language=\"Japanese\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geN12guuqcoj",
        "outputId": "426ea0d8-4584-47f5-938f-caf454bb32c6"
      },
      "outputs": [],
      "source": [
        "system_template=\"You are a professional translator that translates {src_lang} to {dst_lang}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "human_template=\"{user_input}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "chat_prompt.format_prompt(\n",
        "    src_lang=\"English\",\n",
        "    dst_lang=\"Chinese\",\n",
        "    user_input=\"Did you eat in this morning?\"\n",
        ").to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "GSnhADzDwKvP",
        "outputId": "bacd7d10-4147-4067-f61a-3bb814c40ba4"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
        "\n",
        "\n",
        "examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\"},\n",
        "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
        "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
        "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
        "]\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    # 可选的样本数据\n",
        "    examples=examples,\n",
        "    # 提示词模版\n",
        "    example_prompt=example_prompt,\n",
        "    # 格式化的样本数据的最大长度，通过get_text_length函数来衡量\n",
        "    max_length=25,\n",
        "    # get_text_length: ...\n",
        ")\n",
        "dynamic_prompt = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    suffix=\"Input: {adjective}\\nOutput:\",\n",
        "    input_variables=[\"adjective\"],\n",
        ")\n",
        "\n",
        "dynamic_prompt.format(adjective=\"big\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOGB/4NLIJ2sfWa+yQFGuhp",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
