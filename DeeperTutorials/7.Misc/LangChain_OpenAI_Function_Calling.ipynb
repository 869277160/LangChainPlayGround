{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/LangChain-Tutorials/blob/main/LangChain_OpenAI_Function_Calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ubbA-Eeluo1V"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -angchain (d:\\anaconda3\\envs\\llm\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -angchain (d:\\anaconda3\\envs\\llm\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai --upgrade --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRx_yOHMU-FP"
      },
      "source": [
        "# OpenAI重大更新\n",
        "\n",
        "## 2023-06-13 函数调用和其他API更新\n",
        "\n",
        "[Function calling and other API updates](https://openai.com/blog/function-calling-and-other-api-updates)\n",
        "\n",
        "一些令人兴奋的更新：\n",
        "\n",
        "- 在Chat Completions API中新增了函数调用功能。\n",
        "- 更新了更可控的gpt-4和gpt-3.5-turbo版本。\n",
        "- 新增了gpt-3.5-turbo的16k上下文版本（相对于标准的4k版本）。\n",
        "- 我们的最先进的嵌入模型成本降低了75%。\n",
        "- gpt-3.5-turbo的输入令牌成本降低了25%。\n",
        "- 公布了gpt-3.5-turbo-0301和gpt-4-0314模型的停用时间表。\n",
        "\n",
        "**函数调用**功能使我们能够利用模型的自然语言理解能力，将人类语言有效地转化为结构化数据或在我们的代码中进行特定的函数调用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfTMkMDnWIc6"
      },
      "source": [
        "### 基于OpenAI的Python SDK使用函数调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6QU36FDAlSoU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
            "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lenovo\\Desktop\\LangChainPlayGround\\DeeperTutorials\\.env\n",
            "sk-lANo2jIeCWQt94UCCf5d16B7C32744279bF98b06C822D519\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os,sys\n",
        "import openai\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "# sys.path.append(\"../..\")\n",
        "\n",
        "# 读取本地/项目的环境变量。\n",
        "\n",
        "# find_dotenv()寻找并定位.env文件的路径\n",
        "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中  \n",
        "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
        "print(find_dotenv())\n",
        "_ = load_dotenv(find_dotenv())\n",
        "print(os.environ[\"OPENAI_API_KEY\"])\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
        "\n",
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yXS01m6D6hoM"
      },
      "outputs": [],
      "source": [
        "function_descriptions = [\n",
        "  {\n",
        "      \"name\": \"get_student_score\",\n",
        "      \"description\": \"Get the student score by given his or her name\",\n",
        "      \"parameters\": {\n",
        "          \"type\": \"object\",\n",
        "          \"properties\": {\n",
        "              \"name\": {\n",
        "                  \"type\": \"string\",\n",
        "                  \"description\": \"The student's name\",\n",
        "              }\n",
        "          },\n",
        "          \"required\": [\"name\"],\n",
        "      },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZwhqCaeN6qxx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# messages = [\n",
        "#     # SystemMessage(content=\"you are an unhelpful assistent for human, whenever a human say hi to you, you should say \\\" i Am JusT fine!!!!\"),\n",
        "#     # HumanMessage(content=\"Hi, I am a human, how are you today?\"),\n",
        "#     HumanMessage(content = \"\"\"\n",
        "#                  the alice scored 100, the bob scored 20, lucy's score is the average of alice and bob.\n",
        "#                  What's the performance of Lucy in the school this year?\n",
        "#                  \"\"\"),\n",
        "# ]\n",
        "\n",
        "# user_query = \"\"\n",
        "\n",
        "#     functions=function_descriptions,\n",
        "#     function_call=\"auto\",\n",
        "# )\n",
        "user_query = \" the alice scored 100, the bob scored 20, lucy's score is the average of alice and bob.What's the performance of Lucy in the school this year?\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [{\"role\": \"user\", \"content\": user_query}],\n",
        "    functions=function_descriptions,\n",
        "    function_call=\"auto\",\n",
        ")\n",
        "\n",
        "\n",
        "# chat_llm = ChatOpenAI()\n",
        "# chat_llm.bind(function_call=\"auto\",functions=function_descriptions,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TmY2L8S6sfu",
        "outputId": "ea415832-41bc-48cf-f057-5faad284a059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"role\": \"assistant\",\n",
            "  \"content\": null,\n",
            "  \"function_call\": {\n",
            "    \"name\": \"get_student_score\",\n",
            "    \"arguments\": \"{\\n  \\\"name\\\": \\\"Lucy\\\"\\n}\"\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"id\": \"chatcmpl-7o6NNYZ2U8pSZQcwqHTGBsHSBQWFz\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1692175265,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": null,\n",
            "        \"function_call\": {\n",
            "          \"name\": \"get_student_score\",\n",
            "          \"arguments\": \"{\\n  \\\"name\\\": \\\"Lucy\\\"\\n}\"\n",
            "        }\n",
            "      },\n",
            "      \"finish_reason\": \"function_call\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 92,\n",
            "    \"completion_tokens\": 17,\n",
            "    \"total_tokens\": 109\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "ai_response_message = response[\"choices\"][0][\"message\"]\n",
        "print(ai_response_message)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LJeW8xGa6vlZ"
      },
      "outputs": [],
      "source": [
        "name = eval(ai_response_message['function_call']['arguments']).get(\"name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "g94jpgyp-bwm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Lucy'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0Hh2KajS92tX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "SCORES = { 'Alex': 90, 'Lucy': 60 }\n",
        "def get_student_score(name):\n",
        "\n",
        "    \"\"\"Get the student score by given his or her name\"\"\"\n",
        "\n",
        "    score = {\n",
        "        \"name\": name,\n",
        "        \"score\": SCORES[name]\n",
        "    }\n",
        "    return json.dumps(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TbNNhRzx7KLt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"name\": \"Lucy\", \"score\": 60}'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function_response = get_student_score(name=name)\n",
        "\n",
        "function_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Lb86hriN7RXR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-7o6Pwy1sEvAKxf486CA3XGwysNPfp\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1692175424,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"The performance of Lucy in the school this year is 60.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 81,\n",
            "    \"completion_tokens\": 13,\n",
            "    \"total_tokens\": 94\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "second_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user_query},\n",
        "        ai_response_message,\n",
        "        {\n",
        "            \"role\": \"function\",\n",
        "            \"name\": \"get_student_score\",\n",
        "            \"content\": function_response,\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "print(second_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TCtc3z2o7U3O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The performance of Lucy in the school this year is 60.\n"
          ]
        }
      ],
      "source": [
        "print (second_response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlhXtIMxWZtD"
      },
      "source": [
        "### 基于LangChain框架使用函数调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KaAuKKAYvH-J"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
        "from langchain.tools import format_tool_to_openai_function, YouTubeSearchTool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xZF8GCXevKmF"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T4v7FXEWoAI"
      },
      "source": [
        "#### LangChain工具(Tool)的OpenAI函数调用能力"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-HUoZgHavMd4"
      },
      "outputs": [],
      "source": [
        "tools = [YouTubeSearchTool()]\n",
        "functions = [format_tool_to_openai_function(t) for t in tools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IJAVCMCesbsD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'youtube_search',\n",
              "  'description': 'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional',\n",
              "  'parameters': {'properties': {'__arg1': {'title': '__arg1',\n",
              "     'type': 'string'}},\n",
              "   'required': ['__arg1'],\n",
              "   'type': 'object'}}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RXkzJV-lvPaJ"
      },
      "outputs": [],
      "source": [
        "message = llm.predict_messages([HumanMessage(content='search videos in the topic of OpenAI on Youtube')], functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eim7cTNvvRkL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'function_call': {'name': 'youtube_search',\n",
              "  'arguments': '{\\n  \"arg1\": \"OpenAI\"\\n}'}}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message.additional_kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCAZLiZoWyH8"
      },
      "source": [
        "#### LangChain使用OpenAI函数调用实例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EUR3ow27vVdr"
      },
      "outputs": [],
      "source": [
        "function_descriptions = [\n",
        "    {\n",
        "        \"name\": \"remove_word_from_string\",\n",
        "        \"description\": \"Remove a word from a string by given its index\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"string\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The original string to be processed\",\n",
        "                },\n",
        "                \"index\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"The index of the word to be removed\"\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\n",
        "                \"string\",\n",
        "                \"index\"\n",
        "            ],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"send_message_by_email\",\n",
        "        \"description\": \"Send an email with the text message to a recipient\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"recipient\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The email address of the recipient\",\n",
        "                },\n",
        "                \"message\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The message of the email content\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\n",
        "                \"recipient\",\n",
        "                \"message\"\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wX0Vi0GVvXfF"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "I have a string as follows:\n",
        "\n",
        "black yellow red blue green\n",
        "\n",
        "Please do the following 2 operations on it:\n",
        "1. Remove the third word in the string\n",
        "2. Send the updated string to Alex via email alex@xyz.com\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWQFJ0OaLT4N"
      },
      "source": [
        "Helper functions to get function parameter names. They will be used to implement dynamic function calls in Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7Z9GjqAgLYFq"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "\n",
        "def get_function_parameter_names(function):\n",
        "  if function is not None and inspect.isfunction(function):\n",
        "      parameter_names = inspect.signature(function).parameters.keys()\n",
        "      return list(parameter_names)\n",
        "  else:\n",
        "      return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZW_YcePsLZV8"
      },
      "outputs": [],
      "source": [
        "def remove_word_from_string(string, index):\n",
        "    words = string.split()\n",
        "\n",
        "    if 0 <= index < len(words):\n",
        "        del words[index]\n",
        "\n",
        "        return ' '.join(words)\n",
        "    else:\n",
        "        return string\n",
        "\n",
        "def send_message_by_email(recipient, message):\n",
        "    print(f'Sending {message} to {recipient}')\n",
        "    return f'Just sent email to {recipient}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5Rp8oAxLkgA",
        "outputId": "a40a758a-ccbb-4c0d-f7c5-d89792cea2c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['string', 'index']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameter_names = get_function_parameter_names(remove_word_from_string)\n",
        "parameter_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKDhcFLjvZzR",
        "outputId": "51b52683-ad91-41ff-91f0-cb6081581ed5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'remove_word_from_string', 'arguments': '{\\n\"string\": \"black yellow red blue green\",\\n\"index\": 2\\n}'}}, example=False)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_response = llm.predict_messages([HumanMessage(content=question)], functions=function_descriptions)\n",
        "first_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avfWX8RlvbVN",
        "outputId": "db308331-5800-4622-b1aa-97ed06b2634f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'function_call': {'name': 'remove_word_from_string',\n",
              "  'arguments': '{\\n\"string\": \"black yellow red blue green\",\\n\"index\": 2\\n}'}}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_response.additional_kwargs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KbT440rwvdIR"
      },
      "outputs": [],
      "source": [
        "# Get function name, and its arguments\n",
        "\n",
        "function_name = first_response.additional_kwargs[\"function_call\"][\"name\"]\n",
        "arguments = json.loads(first_response.additional_kwargs[\"function_call\"][\"arguments\"])\n",
        "\n",
        "# Locate the function and make the call\n",
        "the_function = globals().get(function_name)\n",
        "parameter_names = get_function_parameter_names(the_function)\n",
        "parameter_values = []\n",
        "for parameter_name in parameter_names:\n",
        "  parameter_values.append(arguments[parameter_name])\n",
        "\n",
        "returned_value = the_function(*parameter_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyDi8HFNR2AP",
        "outputId": "f226a3f1-63f0-4789-c7a6-63657ed0b60c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "black yellow blue green\n"
          ]
        }
      ],
      "source": [
        "print(returned_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "He9SO-aRviNi"
      },
      "outputs": [],
      "source": [
        "second_response = llm.predict_messages(\n",
        "    [\n",
        "        HumanMessage(content=question),\n",
        "        AIMessage(content=str(first_response.additional_kwargs)),\n",
        "        ChatMessage(\n",
        "            role='function',\n",
        "            additional_kwargs = {'name': function_name},\n",
        "            content = returned_value\n",
        "        )\n",
        "    ],\n",
        "    functions=function_descriptions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDIOnSVJvkCw",
        "outputId": "bcff9ca6-18cd-47e7-cbde-cb3020ee1049"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'function_call': {'name': 'send_message_by_email',\n",
              "  'arguments': '{\\n  \"recipient\": \"alex@xyz.com\",\\n  \"message\": \"black yellow blue green\"\\n}'}}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "second_response.additional_kwargs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IGmrBfsmCxv5",
        "outputId": "79ba3bd0-d36c-4a66-ebd3-463eed5c7b9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The updated string after removing the third word is \"black yellow blue green\". \\n\\nNow I will send the updated string to Alex via email.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "second_response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnxm88ivvmCE",
        "outputId": "10793fa3-6509-4ac8-fc2f-982a78849ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending black yellow blue green to alex@xyz.com\n"
          ]
        }
      ],
      "source": [
        "# Again get function name, and its arguments\n",
        "\n",
        "function_name = second_response.additional_kwargs[\"function_call\"][\"name\"]\n",
        "arguments = json.loads(second_response.additional_kwargs[\"function_call\"][\"arguments\"])\n",
        "\n",
        "# Locate the function and make the call\n",
        "the_function = globals().get(function_name)\n",
        "parameter_names = get_function_parameter_names(the_function)\n",
        "parameter_values = []\n",
        "for parameter_name in parameter_names:\n",
        "  parameter_values.append(arguments[parameter_name])\n",
        "\n",
        "returned_value = the_function(*parameter_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmQHgIMESjDB",
        "outputId": "be6377a1-454a-472e-8966-17e4204874d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Just sent email to alex@xyz.com\n"
          ]
        }
      ],
      "source": [
        "# Print the returned value in the second function call\n",
        "print(returned_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "fwQ06ZiIvofH"
      },
      "outputs": [],
      "source": [
        "third_response = llm.predict_messages(\n",
        "    [\n",
        "        HumanMessage(content=question),\n",
        "        AIMessage(content=str(first_response.additional_kwargs)),\n",
        "        AIMessage(content=str(second_response.additional_kwargs)),\n",
        "        ChatMessage(\n",
        "            role='function',\n",
        "            additional_kwargs = {'name': function_name},\n",
        "            content = returned_value\n",
        "        )\n",
        "    ], functions=function_descriptions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bQoHrz2vqP3",
        "outputId": "890ad015-2c65-43ac-e56b-64e7c237013f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='I have removed the third word from the string and sent the updated string \"black yellow blue green\" to Alex via email at alex@xyz.com.', additional_kwargs={}, example=False)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "third_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ2TeDb7bVQ1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPzf1mcXxiTaX9ZTHRySdHi",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
