{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d615a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in d:\\anaconda3\\envs\\llm\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from pinecone-client) (6.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from pinecone-client) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from pinecone-client) (4.7.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from pinecone-client) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from pinecone-client) (1.26.16)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from pinecone-client) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from pinecone-client) (1.23.5)\n",
      "Requirement already satisfied: colorama>=0.3.4 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -angchain (d:\\anaconda3\\envs\\llm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -angchain (d:\\anaconda3\\envs\\llm\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# pip install langchain --upgrade\n",
    "# Version: 0.0.164\n",
    "\n",
    "\n",
    "# !pip install pypdf\n",
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166d759",
   "metadata": {},
   "source": [
    "### Load your data\n",
    "\n",
    "### Chunk your data up into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237060c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\llms\\openai.py:201: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\llms\\openai.py:786: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "import os, sys\n",
    "import openai\n",
    "import langchain\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "\n",
    "\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"] # 换成代理，一定要加v1\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    ")\n",
    "# Turn your texts into embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# pip install unstructured\n",
    "# Other dependencies to install https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/unstructured_file.html\n",
    "# pip install python-magic-bin\n",
    "# pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3e92ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 126 document(s) in your data\n",
      "There are 2812 characters in your document\n",
      "Now you have 162 documents\n"
     ]
    }
   ],
   "source": [
    "# PDF Loaders. If unstructured gives you a hard time, try PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "## options for loaders \n",
    "loader = PyPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "# loader = UnstructuredPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "# loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")\n",
    "data = loader.load()\n",
    "# Note: If you're using PyPDFLoader then it will split by page for you already\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[30].page_content)} characters in your document')\n",
    "\n",
    "\n",
    "# Note: If you're using PyPDFLoader then we'll be splitting for the 2nd time.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b2843",
   "metadata": {},
   "source": [
    "### Create embeddings of your documents to get ready for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373e695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    # api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=\"asia-southeast1-gcp\"  # next to api key in console\n",
    ")\n",
    "index_name = \"langchaintest\" # put in the name of your pinecone index here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0deb2f6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No active indexes found in your Pinecone project, are you sure you're using the right API key and environment?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m docsearch \u001b[39m=\u001b[39m Pinecone\u001b[39m.\u001b[39;49mfrom_texts([t\u001b[39m.\u001b[39;49mpage_content \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m texts], embedding_model, index_name\u001b[39m=\u001b[39;49mindex_name)\n\u001b[0;32m      2\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat are examples of good data science teams?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m docs \u001b[39m=\u001b[39m docsearch\u001b[39m.\u001b[39msimilarity_search(query)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\vectorstores\\pinecone.py:358\u001b[0m, in \u001b[0;36mPinecone.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, index_name, namespace, upsert_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m     index \u001b[39m=\u001b[39m pinecone\u001b[39m.\u001b[39mIndex(index_name)\n\u001b[0;32m    357\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(indexes) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    359\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo active indexes found in your Pinecone project, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mare you sure you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre using the right API key and environment?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n\u001b[0;32m    362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    364\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIndex \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mindex_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not found in your Pinecone project. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDid you mean one of the following indexes: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(indexes)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: No active indexes found in your Pinecone project, are you sure you're using the right API key and environment?"
     ]
    }
   ],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embedding_model, index_name=index_name)\n",
    "query = \"What are examples of good data science teams?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "\n",
    "# Here's an example of the first document that was returned\n",
    "print(docs[0].page_content[:450])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35dcd9",
   "metadata": {},
   "source": [
    "### Query those docs to get your answer back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f051337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b9b1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67ea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the collect stage of data maturity?\"\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dfd2b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The collect stage of data maturity focuses on collecting internal or external datasets. Gathering sales records and corresponding weather data is an example of the collect stage.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
